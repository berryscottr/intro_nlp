{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Chatbot - Scott Berry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Part 1 - Exploratory Data Analysis\n",
    "\n",
    "How many samples/rows in the dataset?\n",
    "\n",
    "-- There are 500 samples of science questions with multiple choices. The dataset provides the correct answer as well.\n",
    "\n",
    "-- There are 1326 samples of factual free response science answers.\n",
    "\n",
    "How many empty rows (e.g. missing text entries)?\n",
    "\n",
    "-- There are no missing entries.\n",
    "\n",
    "What is your source and target?\n",
    "\n",
    "-- There are two different types of datasets:\n",
    "\n",
    "---- The first is question > answer in the form of multiple choice\n",
    "\n",
    "---- The second ii statement > label/description in the form of factual statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Part 2 - Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('water', 124), ('used', 109), ('object', 105), ('causes', 88), ('environment', 81), ('energy', 76), ('food', 74), ('source', 68), ('animal', 66), ('increases', 66), ('animals', 64), ('something', 60), ('light', 57), ('heat', 53), ('earth', 51), ('cause', 51), ('increase', 50), ('plant', 49), ('organism', 48), ('example', 46)]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import vec as vec\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "from nltk import collections\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# load openbook_txt\n",
    "with open(\"OpenBookQA/data/OpenBookQA-V1-Sep2018/Data/Main/openbook.txt\") as openbook_txt:\n",
    "    openbook = openbook_txt.read()\n",
    "with open(\"OpenBookQA/data/OpenBookQA-V1-Sep2018/Data/Main/openbook.txt\") as openbook_txt:\n",
    "    openbook_lines = openbook_txt.readlines()\n",
    "\n",
    "def normalize(text):\n",
    "    tokenized_sentences = [word_tokenize(t) for t in sent_tokenize(openbook)]\n",
    "    words = [word for sentence in tokenized_sentences for word in sentence]\n",
    "    words = [word.lower() for word in words if word.isalpha()]\n",
    "    stop_words = stopwords.words('english')\n",
    "    filtered_words = [w for w in words if w not in stop_words]\n",
    "    return filtered_words, words\n",
    "\n",
    "# tokenize words\n",
    "filtered_words, words = normalize(openbook)\n",
    "# top 20 words\n",
    "word_counts = collections.Counter(filtered_words)\n",
    "print(word_counts.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "These frequent words indicate that the natural world and how\n",
    "matter interacts will be described by the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of each word: 6.5051346100471825\n",
      "Length of each sentence: 9.334841628959277\n",
      "Lexical Diversity:\n",
      "adventure 0.1125\n",
      "belles_lettres 0.2\n",
      "editorial 0.1125\n",
      "fiction 0.11666666666666667\n",
      "government 0.125\n",
      "hobbies 0.11666666666666667\n",
      "humor 0.1\n",
      "learned 0.11666666666666667\n",
      "lore 0.1\n",
      "mystery 0.11666666666666667\n",
      "news 0.1\n",
      "religion 0.11428571428571428\n",
      "reviews 0.11666666666666667\n",
      "romance 0.1\n",
      "science_fiction 0.16666666666666669\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# length of word, length of sentence,  lexical diversity\n",
    "filtered_chars = [list(word) for word in filtered_words]\n",
    "flattened_chars = [item for sublist in filtered_chars for item in sublist]\n",
    "word_length = len(flattened_chars) / len(filtered_words)\n",
    "print(\"Length of each word:\", word_length)\n",
    "sentence_length = len(words) / len(openbook_lines)\n",
    "print(\"Length of each sentence:\", sentence_length)\n",
    "print(\"Lexical Diversity:\")\n",
    "def lexical_diversity(text):\n",
    "    return len(text) / len(set(text))\n",
    "for cat in nltk.corpus.brown.categories():\n",
    "    print(cat, (lexical_diversity(cat) / 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        0     1     2     3            4       5     6     7     8     9      \\\nWord        a   bee    is     a  pollinating  animal     a  bird    is     a   \nPOS tag    DT    NN   VBZ    DT          VBG      RP    DT    NN   VBZ    DT   \n\n         ...       12368      12369    12370 12371  12372  12373       12374  \\\nWord     ...  transports  materials  through   the  plant  young  amphibians   \nPOS tag  ...         NNS        NNS       IN    DT     NN     JJ         NNS   \n\n           12375    12376  12377  \nWord     breathe  through  gills  \nPOS tag      VBP       IN    NNS  \n\n[2 rows x 12378 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>12368</th>\n      <th>12369</th>\n      <th>12370</th>\n      <th>12371</th>\n      <th>12372</th>\n      <th>12373</th>\n      <th>12374</th>\n      <th>12375</th>\n      <th>12376</th>\n      <th>12377</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Word</th>\n      <td>a</td>\n      <td>bee</td>\n      <td>is</td>\n      <td>a</td>\n      <td>pollinating</td>\n      <td>animal</td>\n      <td>a</td>\n      <td>bird</td>\n      <td>is</td>\n      <td>a</td>\n      <td>...</td>\n      <td>transports</td>\n      <td>materials</td>\n      <td>through</td>\n      <td>the</td>\n      <td>plant</td>\n      <td>young</td>\n      <td>amphibians</td>\n      <td>breathe</td>\n      <td>through</td>\n      <td>gills</td>\n    </tr>\n    <tr>\n      <th>POS tag</th>\n      <td>DT</td>\n      <td>NN</td>\n      <td>VBZ</td>\n      <td>DT</td>\n      <td>VBG</td>\n      <td>RP</td>\n      <td>DT</td>\n      <td>NN</td>\n      <td>VBZ</td>\n      <td>DT</td>\n      <td>...</td>\n      <td>NNS</td>\n      <td>NNS</td>\n      <td>IN</td>\n      <td>DT</td>\n      <td>NN</td>\n      <td>JJ</td>\n      <td>NNS</td>\n      <td>VBP</td>\n      <td>IN</td>\n      <td>NNS</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 12378 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Earth', 'LOC')]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"></br>&quot;A bee is a pollinating animal&quot;</br>&quot;A bird is a pollinating animal&quot;</br>&quot;An electrical conductor is a vehicle for the flow of electricity&quot;</br>&quot;An example of a change in the \n<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Earth\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n</mark>\n is an ocean becoming a wooded area&quot;</br>&quot;An example of a chemical change is acid breaking down substances&quot;</br>&quot;An example of a fossil is a footprint in a rock&quot;</br>&quot;An example of a fossil is a paw print in rock&quot;</br>&quot;An example of a fossil is the bones of an extinct animal&quot;</br>&quot;An example of a mixture is clay mixed together&quot;</br>&quot;An example of a reproductive behavior is salmon returning to their birthplace to lay their eggs&quot;</br></div></span>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "from nltk import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "sample = \"\"\"\n",
    "\"A bee is a pollinating animal\"\n",
    "\"A bird is a pollinating animal\"\n",
    "\"An electrical conductor is a vehicle for the flow of electricity\"\n",
    "\"An example of a change in the Earth is an ocean becoming a wooded area\"\n",
    "\"An example of a chemical change is acid breaking down substances\"\n",
    "\"An example of a fossil is a footprint in a rock\"\n",
    "\"An example of a fossil is a paw print in rock\"\n",
    "\"An example of a fossil is the bones of an extinct animal\"\n",
    "\"An example of a mixture is clay mixed together\"\n",
    "\"An example of a reproductive behavior is salmon returning to their birthplace to lay their eggs\"\n",
    "\"\"\"\n",
    "\n",
    "filtered_words, words = normalize(sample)\n",
    "\n",
    "# stemmer, lemmatizer, POS tags, NER\n",
    "ps = PorterStemmer()\n",
    "ps_stemmed = [ps.stem(word) for word in filtered_words]\n",
    "# print(ps_stemmed)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized = [lemmatizer.lemmatize(w) for w in filtered_words]\n",
    "# print(lemmatized)\n",
    "pos_tags = nltk.pos_tag(words)\n",
    "pos_df = pd.DataFrame(pos_tags, columns=['Word', 'POS tag']).T\n",
    "display(pos_df)\n",
    "\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "ner = spacy.load('en_core_web_sm')\n",
    "doc = ner(sample)\n",
    "print([(X.text, X.label_) for X in doc.ents])\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        0     1     2     3            4       5     6     7     8     9      \\\nWord        a   bee    is     a  pollinating  animal     a  bird    is     a   \nPOS tag    DT    NN   VBZ    DT          VBG      RP    DT    NN   VBZ    DT   \n\n         ...       12368      12369    12370 12371  12372  12373       12374  \\\nWord     ...  transports  materials  through   the  plant  young  amphibians   \nPOS tag  ...         NNS        NNS       IN    DT     NN     JJ         NNS   \n\n           12375    12376  12377  \nWord     breathe  through  gills  \nPOS tag      VBP       IN    NNS  \n\n[2 rows x 12378 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>12368</th>\n      <th>12369</th>\n      <th>12370</th>\n      <th>12371</th>\n      <th>12372</th>\n      <th>12373</th>\n      <th>12374</th>\n      <th>12375</th>\n      <th>12376</th>\n      <th>12377</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Word</th>\n      <td>a</td>\n      <td>bee</td>\n      <td>is</td>\n      <td>a</td>\n      <td>pollinating</td>\n      <td>animal</td>\n      <td>a</td>\n      <td>bird</td>\n      <td>is</td>\n      <td>a</td>\n      <td>...</td>\n      <td>transports</td>\n      <td>materials</td>\n      <td>through</td>\n      <td>the</td>\n      <td>plant</td>\n      <td>young</td>\n      <td>amphibians</td>\n      <td>breathe</td>\n      <td>through</td>\n      <td>gills</td>\n    </tr>\n    <tr>\n      <th>POS tag</th>\n      <td>DT</td>\n      <td>NN</td>\n      <td>VBZ</td>\n      <td>DT</td>\n      <td>VBG</td>\n      <td>RP</td>\n      <td>DT</td>\n      <td>NN</td>\n      <td>VBZ</td>\n      <td>DT</td>\n      <td>...</td>\n      <td>NNS</td>\n      <td>NNS</td>\n      <td>IN</td>\n      <td>DT</td>\n      <td>NN</td>\n      <td>JJ</td>\n      <td>NNS</td>\n      <td>VBP</td>\n      <td>IN</td>\n      <td>NNS</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 12378 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Earth', 'LOC')]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"></br>&quot;A bee is a pollinating animal&quot;</br>&quot;A bird is a pollinating animal&quot;</br>&quot;An electrical conductor is a vehicle for the flow of electricity&quot;</br>&quot;An example of a change in the \n<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Earth\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n</mark>\n is an ocean becoming a wooded area&quot;</br>&quot;An example of a chemical change is acid breaking down substances&quot;</br>&quot;An example of a fossil is a footprint in a rock&quot;</br>&quot;An example of a fossil is a paw print in rock&quot;</br>&quot;An example of a fossil is the bones of an extinct animal&quot;</br>&quot;An example of a mixture is clay mixed together&quot;</br>&quot;An example of a reproductive behavior is salmon returning to their birthplace to lay their eggs&quot;</br></div></span>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "\n",
    "# random sample\n",
    "\n",
    "random_sample = \"a cavern is formed by carbonic acid in groundwater seeping through rock and dissolving limestone\"\n",
    "\n",
    "filtered_words, words = normalize(random_sample)\n",
    "\n",
    "# stemmer, lemmatizer, POS tags, NER\n",
    "ps = PorterStemmer()\n",
    "ps_stemmed = [ps.stem(word) for word in filtered_words]\n",
    "# print(ps_stemmed)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized = [lemmatizer.lemmatize(w) for w in filtered_words]\n",
    "# print(lemmatized)\n",
    "pos_tags = nltk.pos_tag(words)\n",
    "pos_df = pd.DataFrame(pos_tags, columns=['Word', 'POS tag']).T\n",
    "display(pos_df)\n",
    "\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "ner = spacy.load('en_core_web_sm')\n",
    "doc = ner(sample)\n",
    "print([(X.text, X.label_) for X in doc.ents])\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Samples printed above of Stemmer, Lemmatizer, POS tags, and NER.\n",
    "The results are as expected with the NER being sparse and POS accurately assigning.\n",
    "\n",
    "The function used in this assignment for normalization of text is as follows\n",
    "```\n",
    "def normalize(text):\n",
    "    tokenized_sentences = [word_tokenize(t) for t in sent_tokenize(openbook)]\n",
    "    words = [word for sentence in tokenized_sentences for word in sentence]\n",
    "    words = [word.lower() for word in words if word.isalpha()]\n",
    "    stop_words = stopwords.words('english')\n",
    "    filtered_words = [w for w in words if w not in stop_words]\n",
    "    return filtered_words\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Part 3 - Feature Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      ability  absorb  absorbed  absorbing  absorbs  access  accurately  acid  \\\n0           0       0         0          0        0       0           0     0   \n1           0       0         0          0        0       0           0     0   \n2           0       0         0          0        0       0           0     0   \n3           0       0         0          0        0       0           0     0   \n4           0       0         0          0        0       0           0     0   \n...       ...     ...       ...        ...      ...     ...         ...   ...   \n7201        0       0         0          0        0       0           0     0   \n7202        0       0         0          0        0       0           0     0   \n7203        0       0         0          0        0       0           0     0   \n7204        0       0         0          0        0       0           0     0   \n7205        0       0         0          0        0       0           0     0   \n\n      acorns  acquire  ...  working  world  wrapping  xylem  year  years  \\\n0          0        0  ...        0      0         0      0     0      0   \n1          0        0  ...        0      0         0      0     0      0   \n2          0        0  ...        0      0         0      0     0      0   \n3          0        0  ...        0      0         0      0     0      0   \n4          0        0  ...        0      0         0      0     0      0   \n...      ...      ...  ...      ...    ...       ...    ...   ...    ...   \n7201       0        0  ...        0      0         0      0     0      0   \n7202       0        0  ...        0      0         0      0     0      0   \n7203       0        0  ...        0      0         0      0     0      0   \n7204       0        0  ...        0      0         0      0     0      0   \n7205       0        0  ...        0      0         0      0     0      0   \n\n      young  zero  zinc  zoo  \n0         0     0     0    0  \n1         0     0     0    0  \n2         0     0     0    0  \n3         0     0     0    0  \n4         0     0     0    0  \n...     ...   ...   ...  ...  \n7201      0     0     0    0  \n7202      1     0     0    0  \n7203      0     0     0    0  \n7204      0     0     0    0  \n7205      0     0     0    0  \n\n[7206 rows x 1711 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ability</th>\n      <th>absorb</th>\n      <th>absorbed</th>\n      <th>absorbing</th>\n      <th>absorbs</th>\n      <th>access</th>\n      <th>accurately</th>\n      <th>acid</th>\n      <th>acorns</th>\n      <th>acquire</th>\n      <th>...</th>\n      <th>working</th>\n      <th>world</th>\n      <th>wrapping</th>\n      <th>xylem</th>\n      <th>year</th>\n      <th>years</th>\n      <th>young</th>\n      <th>zero</th>\n      <th>zinc</th>\n      <th>zoo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7201</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7202</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7203</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7204</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7205</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>7206 rows × 1711 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most frequent words: [('water', 124), ('used', 109), ('object', 105), ('causes', 88), ('environment', 81), ('energy', 76), ('food', 74), ('source', 68), ('animal', 66), ('increases', 66)]\n"
     ]
    },
    {
     "data": {
      "text/plain": "      ability  absorb  absorbed  absorbing  absorbs  access  accurately  acid  \\\n0         0.0     0.0       0.0        0.0      0.0     0.0         0.0   0.0   \n1         0.0     0.0       0.0        0.0      0.0     0.0         0.0   0.0   \n2         0.0     0.0       0.0        0.0      0.0     0.0         0.0   0.0   \n3         0.0     0.0       0.0        0.0      0.0     0.0         0.0   0.0   \n4         0.0     0.0       0.0        0.0      0.0     0.0         0.0   0.0   \n...       ...     ...       ...        ...      ...     ...         ...   ...   \n7201      0.0     0.0       0.0        0.0      0.0     0.0         0.0   0.0   \n7202      0.0     0.0       0.0        0.0      0.0     0.0         0.0   0.0   \n7203      0.0     0.0       0.0        0.0      0.0     0.0         0.0   0.0   \n7204      0.0     0.0       0.0        0.0      0.0     0.0         0.0   0.0   \n7205      0.0     0.0       0.0        0.0      0.0     0.0         0.0   0.0   \n\n      acorns  acquire  ...  working  world  wrapping  xylem  year  years  \\\n0        0.0      0.0  ...      0.0    0.0       0.0    0.0   0.0    0.0   \n1        0.0      0.0  ...      0.0    0.0       0.0    0.0   0.0    0.0   \n2        0.0      0.0  ...      0.0    0.0       0.0    0.0   0.0    0.0   \n3        0.0      0.0  ...      0.0    0.0       0.0    0.0   0.0    0.0   \n4        0.0      0.0  ...      0.0    0.0       0.0    0.0   0.0    0.0   \n...      ...      ...  ...      ...    ...       ...    ...   ...    ...   \n7201     0.0      0.0  ...      0.0    0.0       0.0    0.0   0.0    0.0   \n7202     0.0      0.0  ...      0.0    0.0       0.0    0.0   0.0    0.0   \n7203     0.0      0.0  ...      0.0    0.0       0.0    0.0   0.0    0.0   \n7204     0.0      0.0  ...      0.0    0.0       0.0    0.0   0.0    0.0   \n7205     0.0      0.0  ...      0.0    0.0       0.0    0.0   0.0    0.0   \n\n      young  zero  zinc  zoo  \n0       0.0   0.0   0.0  0.0  \n1       0.0   0.0   0.0  0.0  \n2       0.0   0.0   0.0  0.0  \n3       0.0   0.0   0.0  0.0  \n4       0.0   0.0   0.0  0.0  \n...     ...   ...   ...  ...  \n7201    0.0   0.0   0.0  0.0  \n7202    1.0   0.0   0.0  0.0  \n7203    0.0   0.0   0.0  0.0  \n7204    0.0   0.0   0.0  0.0  \n7205    0.0   0.0   0.0  0.0  \n\n[7206 rows x 1711 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ability</th>\n      <th>absorb</th>\n      <th>absorbed</th>\n      <th>absorbing</th>\n      <th>absorbs</th>\n      <th>access</th>\n      <th>accurately</th>\n      <th>acid</th>\n      <th>acorns</th>\n      <th>acquire</th>\n      <th>...</th>\n      <th>working</th>\n      <th>world</th>\n      <th>wrapping</th>\n      <th>xylem</th>\n      <th>year</th>\n      <th>years</th>\n      <th>young</th>\n      <th>zero</th>\n      <th>zinc</th>\n      <th>zoo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7201</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7202</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7203</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7204</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7205</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>7206 rows × 1711 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most frequent words: [('water', 124), ('used', 109), ('object', 105), ('causes', 88), ('environment', 81), ('energy', 76), ('food', 74), ('source', 68), ('animal', 66), ('increases', 66)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# load openbook_txt\n",
    "with open(\"OpenBookQA/data/OpenBookQA-V1-Sep2018/Data/Main/openbook.txt\") as openbook_txt:\n",
    "    openbook = openbook_txt.read()\n",
    "with open(\"OpenBookQA/data/OpenBookQA-V1-Sep2018/Data/Main/openbook.txt\") as openbook_txt:\n",
    "    openbook_lines = openbook_txt.readlines()\n",
    "\n",
    "def normalize(text):\n",
    "    tokenized_sentences = [word_tokenize(t) for t in sent_tokenize(openbook)]\n",
    "    words = [word for sentence in tokenized_sentences for word in sentence]\n",
    "    words = [word.lower() for word in words if word.isalpha()]\n",
    "    stop_words = stopwords.words('english')\n",
    "    filtered_words = [w for w in words if w not in stop_words]\n",
    "    return filtered_words, words\n",
    "\n",
    "# tokenize words\n",
    "filtered_words, words = normalize(openbook)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "cv = CountVectorizer(min_df=0., max_df=1.)\n",
    "cv_matrix = cv.fit_transform(filtered_words)\n",
    "cv_matrix = cv_matrix.toarray()\n",
    "vocab = cv.get_feature_names()\n",
    "cv_df = pd.DataFrame(cv_matrix, columns=vocab)\n",
    "display(cv_df)\n",
    "\n",
    "vec = CountVectorizer()\n",
    "vec.fit(filtered_words)\n",
    "bag_of_words = vec.transform(filtered_words)\n",
    "sum_words = bag_of_words.sum(axis=0)\n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\n",
    "words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "print(\"10 most frequent words:\", words_freq[:10])\n",
    "\n",
    "tt = TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True)\n",
    "tt_matrix = tt.fit_transform(cv_matrix)\n",
    "tt_matrix = tt_matrix.toarray()\n",
    "vocab = cv.get_feature_names()\n",
    "tt_df = pd.DataFrame(np.round(tt_matrix, 2), columns=vocab)\n",
    "display(tt_df)\n",
    "\n",
    "vec = CountVectorizer()\n",
    "vec.fit(filtered_words)\n",
    "bag_of_words = vec.transform(filtered_words)\n",
    "sum_words = bag_of_words.sum(axis=0)\n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\n",
    "words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "print(\"10 most frequent words:\", words_freq[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Count Vectorizer:\n",
    "\n",
    "Vocabulary size in CV is 1711 words (matrix 1326 x 1711)\n",
    "\n",
    "10 most frequent words: [('water', 124), ('used', 109), ('object', 105), ('causes', 88), ('environment', 81), ('energy', 76), ('food', 74), ('source', 68), ('animal', 66), ('increases', 66)]\n",
    "\n",
    "Tfidf Transformer:\n",
    "\n",
    "Vocabulary size in TF Transform is 1711 words (matrix 1326 x 1711)\n",
    "\n",
    "10 most frequent words: [('water', 124), ('used', 109), ('object', 105), ('causes', 88), ('environment', 81), ('energy', 76), ('food', 74), ('source', 68), ('animal', 66), ('increases', 66)]\n",
    "\n",
    "The Tfidf Transform gives the same results as the Count Vectorizer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}