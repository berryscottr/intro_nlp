{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Scott Berry -\n",
    "\n",
    "### Week 8 Assignment 2 CBOW"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 1\n",
    "- Select one of the above speeches\n",
    "- Load a corpus"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package inaugural to\n",
      "[nltk_data]     C:\\Users\\berry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package inaugural is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('inaugural')\n",
    "from nltk.corpus import inaugural\n",
    "\n",
    "names = inaugural.fileids()\n",
    "speech = inaugural.raw(fileids = names[23]) # 1881 Garfield"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 2 Preprocess corpus\n",
    "- Customize or create your own normalization function: you will decide how to clean and preprocess it\n",
    "- Do not print the entire corpus"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from nltk import collections\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "def normalize(text):\n",
    "    tokenized_sentences = [word_tokenize(t) for t in sent_tokenize(text)]\n",
    "    words = [word for sentence in tokenized_sentences for word in sentence]\n",
    "    words = [word.lower() for word in words if word.isalpha()]\n",
    "    stop_words = stopwords.words('english')\n",
    "    filtered_words = [w for w in words if w not in stop_words]\n",
    "    return filtered_words, words\n",
    "\n",
    "# tokenize words\n",
    "filtered_words, words = normalize(speech)\n",
    "# top 20 words\n",
    "word_counts = collections.Counter(filtered_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 3 Vocabulary\n",
    "- Create a corpus vocabulary and a map of words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 4 Context Window\n",
    "- Create a context window and target word generator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 5 CBOW\n",
    "- Build CBOW model\n",
    " - embed_size = 100\n",
    " - window_size = 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 6 Training\n",
    "- Train model at least 5 epoch\n",
    "- Print loss values for each epoch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 7 Search Terms\n",
    "- Extract word embeddings and create a sample with search terms"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 8 Visualization\n",
    "- Visualize distance of word embedding from your sample"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 9 Summary\n",
    "- Write a brief summary, describe decisions on cleaning and preprocessing corpus\n",
    "- Proper markdown formatting, clean code, proper references/citations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}